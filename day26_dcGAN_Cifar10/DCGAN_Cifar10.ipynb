{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "name": "DCGAN_Cifar10.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "TnySQjMJWu5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load in \n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the \"../input/\" directory.\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# Any results you write to the current directory are saved as output."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "trusted": true,
        "id": "pWbbB3Z1Wu6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
        "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
        "from keras.models import Sequential, Model\n",
        "from keras.optimizers import Adam,SGD\n",
        "import keras\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "print(os.listdir(\"../input\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "u6apMFa8Wu6R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from os import listdir, makedirs\n",
        "from os.path import join, exists, expanduser\n",
        "\n",
        "cache_dir = expanduser(join('~', '.keras'))\n",
        "if not exists(cache_dir):\n",
        "    makedirs(cache_dir)\n",
        "datasets_dir = join(cache_dir, 'datasets') # /cifar-10-batches-py\n",
        "if not exists(datasets_dir):\n",
        "    makedirs(datasets_dir)\n",
        "\n",
        "\n",
        "!cp ../input/cifar-10-python.tar.gz ~/.keras/datasets/\n",
        "!ln -s  ~/.keras/datasets/cifar-10-python.tar.gz ~/.keras/datasets/cifar-10-batches-py.tar.gz\n",
        "!tar xzvf ~/.keras/datasets/cifar-10-python.tar.gz -C ~/.keras/datasets/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "GsnTiqQnWu6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(X_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "\n",
        "X_train = X_train[y_train.flatten() == 2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "I9p5fEEwWu6d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input shape\n",
        "img_rows = 32\n",
        "img_cols = 32\n",
        "channels = 3\n",
        "        \n",
        "img_shape = (img_rows, img_cols, channels)        \n",
        "latent_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "KkcBl3evWu6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "\n",
        "# 입력을 16 × 16 크기의 128개 채널을 가진 특성 맵으로 변환합니다\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "\n",
        "# 합성곱 층을 추가합니다\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# 32 × 32 크기로 업샘플링합니다\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# 합성곱 층을 더 추가합니다\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "\n",
        "# 32 × 32 크기의 3개 채널을 가진 특성 맵을 생성합니다\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "AwwoAaMdWu6n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_input = layers.Input(shape=(32, 32, 3))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "\n",
        "# 드롭아웃 층을 넣는 것이 아주 중요합니다!\n",
        "x = layers.Dropout(0.4)(x)\n",
        "\n",
        "# 분류 층\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "T33PwRD-Wu6w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator_optimizer = keras.optimizers.RMSprop(lr=0.0008, clipvalue=1.0, decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "pJFGWI0PWu61",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# discriminator.trainable = False\n",
        "\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "uz9s6BeTWu66",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터를 정규화합니다\n",
        "X_train = X_train.reshape(\n",
        "    (X_train.shape[0],) + (height, width, channels)).astype('float32') / 255.\n",
        "\n",
        "iterations = 5000\n",
        "batch_size = 20\n",
        "save_dir = join(datasets_dir, 'gan_images')\n",
        "if not os.path.exists(save_dir):\n",
        "    os.mkdir(save_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_jmb6z-fWu6_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = (X_train - 0.5) / 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "L86SEaJ3Wu7E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "start = 0\n",
        "for step in range(iterations):\n",
        "    # 잠재 공간에서 무작위로 포인트를 샘플링합니다 latent spacde (20, 100)\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    # 가짜 이미지를 디코딩합니다\n",
        "    generated_images = generator.predict(random_latent_vectors)\n",
        "\n",
        "    # 진짜 이미지와 연결합니다\n",
        "    stop = start + batch_size\n",
        "    real_images = X_train[start: stop]\n",
        "    combined_images = np.concatenate([generated_images, real_images])\n",
        "\n",
        "    # 진짜와 가짜 이미지를 구분하여 레이블을 합칩니다\n",
        "    labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "                             np.zeros((batch_size, 1))])\n",
        "    # 레이블에 랜덤 노이즈를 추가합니다. 아주 중요합니다!\n",
        "#     labels += 0.05 * np.random.random(labels.shape)\n",
        "\n",
        "    # fake 1 / real 0 을 구분할 수 있는 discriminator 학습\n",
        "    d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "\n",
        "    # 잠재 공간에서 무작위로 포인트를 샘플링합니다\n",
        "    random_latent_vectors = np.random.normal(size=(batch_size, latent_dim))\n",
        "\n",
        "    # 모두 “진짜 이미지\"라고 레이블을 만듭니다\n",
        "    misleading_targets = np.zeros((batch_size, 1))\n",
        "\n",
        "    # generator를 훈련합니다(gan 모델에서 discriminator의 가중치는 동결됩니다)\n",
        "    a_loss = gan.train_on_batch(random_latent_vectors, misleading_targets)\n",
        "    \n",
        "    start += batch_size\n",
        "    if start > len(X_train) - batch_size:\n",
        "      start = 0\n",
        "\n",
        "    # 중간 중간 저장하고 그래프를 그립니다\n",
        "    if step % 500 == 0:\n",
        "        # 모델 가중치를 저장합니다\n",
        "        gan.save_weights('gan.h5')\n",
        "\n",
        "        # 측정 지표를 출력합니다\n",
        "        print('스텝 %s에서 판별자 손실: %s' % (step, d_loss))\n",
        "        print('스텝 %s에서 적대적 손실: %s' % (step, a_loss))\n",
        "\n",
        "        # 생성된 이미지 하나를 저장합니다\n",
        "        img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'generated_frog' + str(step) + '.png'))\n",
        "\n",
        "        # 비교를 위해 진짜 이미지 하나를 저장합니다\n",
        "        img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "        img.save(os.path.join(save_dir, 'real_frog' + str(step) + '.png'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "O-k93K96Wu7L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "s=X_train[:40]\n",
        "s = (s * 0.5) + 0.5\n",
        "\n",
        "f, ax = plt.subplots(5,8, figsize=(16,10))\n",
        "for i, img in enumerate(s):\n",
        "        ax[i//8, i%8].imshow(img)\n",
        "        ax[i//8, i%8].axis('off')\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "faxzIzqrWu7P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "noise = np.random.normal(size=(40, latent_dim))\n",
        "generated_images = generator.predict(noise)\n",
        "generated_images = 0.5 * generated_images + 0.5\n",
        "\n",
        "f, ax = plt.subplots(5,8, figsize=(16,10))\n",
        "for i, img in enumerate(generated_images):\n",
        "        ax[i//8, i%8].imshow(img)\n",
        "        ax[i//8, i%8].axis('off')\n",
        "        \n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "Qa4zFKPaWu7W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}